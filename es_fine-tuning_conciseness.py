"""
ES fine tuning of LLMs
"""

import argparse
import gc
import os
import time
from concurrent.futures import ThreadPoolExecutor

import numpy as np
import torch
import torch.multiprocessing as mp
from accelerate import Accelerator
from transformers import AutoModelForCausalLM
from transformers import AutoTokenizer
from transformers.utils import logging

# Set the Hugging Face Transformers logger to show only errors
logging.set_verbosity_error()

# Controls whether TF32 operations are allowed on NVIDIA Ampere GPUs (e.g., A100, H100, etc.).
torch.backends.cuda.matmul.allow_tf32 = True

# XX might want to disbale this, at least during development, to catch important
# warnings (runtime warnings, depreciation warnings, import warnings, etc.)
os.environ["PYTHONWARNINGS"] = "ignore"

# The spawn method is used to start new child processes. It
# starts a fresh, new Python interpreter process. It is the safest
# option for Cuda (Avoids problems with shared memory or state)
mp.set_start_method("spawn", force=True)

# Hyperparameters for ES
NUM_ITERATIONS = 1000  # Number of ES iterations (generations)
POPULATION_SIZE = 30  # Population size (number of perturbations per iteration)
SIGMA = 0.001  # Standard deviation for weight perturbations (noise scale)
ALPHA = 0.0005  # Learning rate
MAX_NEW_TOKENS = 100  # Maximum number of tokens allowed to be generated
DO_SAMPLE = False  # Whether sampling is allowed in generating tokens, default to no (greedy decoding for ES)
INITIAL_SEED = 33  # Initial random seed


# --- Dummy Dataset and Reward Function ---
# In practice, define a set of input reasoning tasks with desired targets.
dataset = [
    ("Solve: 3 + 5 =", "8"),
    ("If all birds can fly and penguins are birds, can penguins fly?", "No"),
]


def parse_args():
    """
    Parse command line arguments and return them
    """
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--model_name",
        type=str,
        default="Qwen/Qwen2.5-3B-Instruct",
        help="Name of the model to fine-tune",
    )
    parser.add_argument(
        "--hf_cache_dir",
        type=str,
        default="huggingface_cache",
        help="HuggingFace cache durectory",
    )

    # Format    Bits  Sign  Exponent  Fraction  Notes
    # FP16      16    1     5         10        Std 16-bit float. Narrow range. Prone to under/overflow. Very fast.
    # BF16      16    1     8         7         "BrainFloat". FP32 range. Less precision. Very fast.
    # TF32      32    1     8         10        "TensorFloat". FP32 range. FP16-like precision. Fast.
    # FP32      32    1     8         23        Std 32-bit float. Normal speed.
    parser.add_argument(
        "--precision",
        type=str,
        default="bf16",
        help="Format for representing floating-point numbers",
    )
    parser.add_argument("--gpu_threads", type=int, default=4, help="Number of parallel threads per GPU")
    parser.add_argument("--verbose", action="store_true", help="Print verbose logs")
    parser.add_argument("--seed_shift", action="store_true", help="Add a fixed offset to random number generator seed")
    args = parser.parse_args()

    return args


def compute_reward(generated_text: str, target_text: str):
    """
    Compute the reward

    :param generated_text : The text generated by the model

    :param target_text : The expected text to compare against

    :return: The reward value
    """
    # Negative absolute difference in length
    return -abs(len(generated_text) - len(target_text))


def force_memory_cleanup():
    """
    Manually clear memory on both CPU and GPU
    """
    # Free unused CPU-side objects
    gc.collect()

    if torch.cuda.is_available():
        # Free cached GPU memory
        torch.cuda.empty_cache()

        # Free inter-process communication (IPC) memory handles on the GPU
        torch.cuda.ipc_collect()

        # Waits for all GPU operations to finish. By default, CUDA operations in PyTorch (e.g., .to(device)) are
        # asynchronous — the CPU tells the GPU to “do something” then moves on without waiting for it to finish.
        torch.cuda.synchronize()


def evaluate_model(  # pylint: disable=too-many-arguments,disable=too-many-positional-arguments,disable=too-many-locals
    model,
    tokenizer: AutoTokenizer,
    input_text: str | list[str],
    target_text: str | list[str],
    accelerator: Accelerator,
    seed_idx: torch.long = None,
    thread_id: int = None,
    verbose: bool = False,
    return_text: bool = False,
):
    """
    Generate a response from the model given an input (single or batch) and compute the rewards.
    """
    if verbose:
        print(f"Process {accelerator.process_index} Thread {thread_id} evaluating seed {seed_idx}")

    # Handle both single input and batch input
    #
    # XX Must add validation to ensure input_text and target_text
    # are both lists of the same size or scalar
    is_batch = isinstance(input_text, list)
    input_texts = input_text if is_batch else [input_text]
    target_texts = target_text if is_batch else [target_text]

    # Batch tokenization
    tokenized_inputs = tokenizer(input_texts, return_tensors="pt", padding=True, padding_side="left")
    input_ids = tokenized_inputs["input_ids"].to(accelerator.device)
    attention_mask = tokenized_inputs["attention_mask"].to(accelerator.device)

    with torch.inference_mode():
        outputs = model.generate(
            input_ids,
            attention_mask=attention_mask,
            max_new_tokens=MAX_NEW_TOKENS,
            do_sample=DO_SAMPLE,
        )
        if torch.cuda.is_available():
            # Blocking call. Tells PyTorch “Stop the CPU right now and wait for the GPU
            # (on this specific device) to finish all its queued work.”
            torch.cuda.synchronize(accelerator.device)

    # Decode batch outputs
    generated_texts = []
    for i in range(len(input_texts)):
        try:
            generated_text = tokenizer.decode(outputs[i], skip_special_tokens=True)
        except TypeError:
            # If we encounter an error, manually reconstruct the text in a more cautious way

            # Map numeric IDs to their string tokens (e.g., "hello", "world", etc.).
            tokens = tokenizer.convert_ids_to_tokens(outputs[i], skip_special_tokens=True)
            # Sometimes tokenization can produce None entries — this filters them out.
            filtered = [t for t in tokens if t is not None]

            # Join tokens back into a readable string — essentially replicating what .decode() does, but safely.
            generated_text = tokenizer.convert_tokens_to_string(filtered)

        generated_texts.append(generated_text)

    del input_ids, outputs
    torch.cuda.empty_cache()

    # Compute rewards for batch texts
    rewards = [compute_reward(gen_text, tgt_text) for gen_text, tgt_text in zip(generated_texts, target_texts)]

    if return_text:
        return rewards, generated_texts
    return rewards


def process_seed(seed_args):  # pylint: disable=too-many-locals
    """Function to process a single seed, used for thread pool"""
    seed_idx, seed, model, tokenizer, accelerator, thread_id, verbose, seed_shift = seed_args

    if verbose:
        print(f"Process {accelerator.process_index} Thread {thread_id} processing seed {seed_idx} (value: {seed})")

    # Weight perturbation
    seed_shift_value = 0
    for _, param in model.named_parameters():
        # Create a random number generator on the same device as the given param
        gen = torch.Generator(device=param.device)

        # Set the random seed for random number generator
        if seed_shift:
            gen.manual_seed(int(seed + seed_shift_value))
        else:
            gen.manual_seed(int(seed))
        seed_shift_value += 1

        noise = torch.randn(param.shape, generator=gen, device=param.device, dtype=param.dtype)

        # Add noise directly to a model parameter’s data in-place — modifying it's tensor values
        # param.data accesses the raw tensor data of the parameter without gradient tracking
        # The trailing _ means this is an in-place operation; it modifies the tensor rather than creating a new one
        param.data.add_(SIGMA * noise)

    # Ensure weights are fully loaded before evaluation
    if torch.cuda.is_available():
        # Synchronize CPU and GPU — but only for the specific device that the Accelerate framework is using
        torch.cuda.synchronize(accelerator.device)

    # Evaluate all prompts with perturbed weights in batch
    # Two list comprehensions to split a dataset of (input, target) pairs into
    # two separate lists — one for inputs and one for targets
    input_texts = [input_text for input_text, _ in dataset]
    target_texts = [target_text for _, target_text in dataset]
    rewards = evaluate_model(
        model,
        tokenizer,
        input_texts,
        target_texts,
        accelerator,
        seed_idx=seed_idx,
        thread_id=thread_id,
        verbose=verbose,
        return_text=False,
    )
    total_reward = sum(rewards)

    # Restore original weights (direct inplace modification)
    seed_shift_value = 0
    for _, param in model.named_parameters():
        gen = torch.Generator(device=param.device)

        if seed_shift:
            gen.manual_seed(int(seed + seed_shift_value))
        else:
            gen.manual_seed(int(seed))
        seed_shift_value += 1

        noise = torch.randn(param.shape, generator=gen, device=param.device, dtype=param.dtype)
        param.data.add_(-SIGMA * noise)

    if torch.cuda.is_available():
        # Synchronize CPU and GPU — but only for the specific device that the Accelerate framework is using
        torch.cuda.synchronize(accelerator.device)

    average_reward = total_reward / len(dataset)

    force_memory_cleanup()

    if verbose:
        print(
            f"Process {accelerator.process_index} Thread {thread_id} completed seed {seed_idx} \
                with reward {average_reward:.4f}"
        )

    return seed_idx, average_reward


def main(args):  # pylint: disable=too-many-locals, too-many-branches, too-many-statements
    """
    Main Evolution Strategies Loop
    """

    # Accelerator helps you run PyTorch training code on any hardware setup — CPU, GPU,
    # or multi-GPU — without rewriting your training loop. It automaticaly handles:
    # 1) Device placement (moves models/data to the right device)
    # 2) Distributed training (multi-GPU or multi-node)
    # 3) Mixed precision (FP16/BF16)
    accelerator = Accelerator()

    # Boolean flag that tells you whether the current process is the main process among
    # all the distributed workers. Only the main process should:
    # 1) Print logs to the console
    # 2) Save checkpoints or models
    # 3) Write to TensorBoard / WandB / files
    if accelerator.is_main_process:
        print(f"Total processes: {accelerator.num_processes}, GPU threads per process: {args.gpu_threads}")
        print(f"Population size: {POPULATION_SIZE}, Iterations: {NUM_ITERATIONS}")
        print(f"Sigma: {SIGMA}, Alpha: {ALPHA}")

    # Load model
    model_name = args.model_name
    hf_cache_dir = args.hf_cache_dir

    if accelerator.is_main_process:
        print(f"Loading model {model_name}...")

    # Load model
    model_list = []
    for _ in range(args.gpu_threads):
        model_list.append(
            AutoModelForCausalLM.from_pretrained(
                model_name,
                cache_dir=hf_cache_dir,
                # device_map is a dictionary that controls how and where the model’s layers are loaded
                # The empty string key ("") refers to the entire model. E.g., if args.gpu_threads = 2,
                # it will create two independent models and append them to model_list.
                device_map={"": accelerator.process_index},  # Assign devices explicitly
                torch_dtype=(
                    torch.float16
                    if args.precision == "fp16"
                    else (torch.bfloat16 if args.precision == "bf16" else torch.float32)
                ),
            )
        )

    # Load tokenizer. Use the slow (Python) version of the tokenizer instead of the fast (Rust-backed) one
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, cache_dir=hf_cache_dir)

    if accelerator.is_main_process:
        print("Model loaded successfully")

    # Prepare model with accelerator
    for model in model_list:
        model.eval()  # Turn off dropout, batch normalizatio, etc.

    force_memory_cleanup()

    # Record total training start time
    training_start_time = time.time()

    np.random.seed(INITIAL_SEED)

    for iteration in range(NUM_ITERATIONS):
        # Record iteration start time
        iter_start_time = time.time()

        # Force garbage collection
        force_memory_cleanup()

        if args.verbose:
            print(f"Process {accelerator.process_index} starting iteration {iteration + 1}/{NUM_ITERATIONS}")

        # Generate seeds on main process only
        if accelerator.is_main_process:
            if args.verbose:
                print(f"Main process {accelerator.process_index} generating seeds")
            seeds = np.random.randint(0, 2**30, size=POPULATION_SIZE, dtype=np.int64).tolist()
            seeds_tensor = torch.tensor(seeds, device=accelerator.device)
        else:
            if args.verbose:
                print(f"Worker process {accelerator.process_index} waiting for seeds")
            # XX Why torch.long and not np.int64?
            seeds_tensor = torch.zeros(POPULATION_SIZE, dtype=torch.long, device=accelerator.device)

        # Broadcast seeds from main process to all processes
        # Checks if the training is running on more than one process — meaning distributed or multi-GPU training.
        if accelerator.num_processes > 1:
            # This is a PyTorch Distributed Data Parallel (DDP) call. It broadcasts a tensor (seeds_tensor) from
            # the source process (src=0, i.e., the main process) to all other processes.
            torch.distributed.broadcast(seeds_tensor, src=0)

        # After the broadcast, all processes now have the same seeds_tensor.
        # This line moves it to CPU memory and converts it into a regular Python list.
        seeds = seeds_tensor.cpu().tolist()

        if args.verbose:
            print(f"Process {accelerator.process_index} received seeds")

        # Assign seeds to each process for processing
        local_seeds = []
        for seed_idx, seed in enumerate(seeds):
            # Simple task assignment: assign seeds by process ID
            if seed_idx % accelerator.num_processes == accelerator.process_index:
                local_seeds.append((seed_idx, seed))

        if args.verbose:
            print(
                f"Process {accelerator.process_index} assigned {len(local_seeds)} \
                    seeds: {[idx for idx, _ in local_seeds]}"
            )

        # Process seeds in smaller batches to reduce memory pressure
        local_rewards = []

        # Suppose, you have 8 local seeds, and 2 GPU threads.
        # Your batch size would be 2, and you'd have to train on 4 batches
        batch_size = max(1, min(args.gpu_threads, len(local_seeds)))

        # Suppose, you have 8 local seeds, 2 GPU threads, and a batch size of 2,
        # and you have to train on 4 batches. Iterate over starting index of the
        # 4 batches (i.e., 0, 2, 4, and 6). Add the batch size to those to slice
        # local_seeds and get seeds for the batch
        for batch_start in range(0, len(local_seeds), batch_size):
            batch_end = min(batch_start + batch_size, len(local_seeds))
            batch_seeds = local_seeds[batch_start:batch_end]

            with ThreadPoolExecutor(max_workers=len(batch_seeds)) as executor:
                # Prepare thread arguments
                thread_args = []
                # XX what is the value of thread_id?
                for thread_id, (seed_idx, seed) in enumerate(batch_seeds):
                    # Pass verbose flag as argument to process_seed function
                    thread_args.append(
                        (
                            seed_idx,
                            seed,
                            model_list[thread_id],
                            tokenizer,
                            accelerator,
                            thread_id,
                            args.verbose,
                            args.seed_shift,
                        )
                    )

                # Execute in parallel and collect results
                results = list(executor.map(process_seed, thread_args))
                local_rewards.extend(results)

            # Clean up between batches
            force_memory_cleanup()

        # Collect rewards from all processes
        all_rewards = torch.zeros(POPULATION_SIZE, device=accelerator.device)

        # Fill in locally computed rewards
        for seed_idx, reward in local_rewards:
            all_rewards[seed_idx] = reward

        # Aggregate rewards from all processes (each process will get the full reward list)
        # Performs a reduction operation (like sum, average, max, etc.) on a tensor across all
        # processes in a distributed group — and then broadcasts the result back to every process.
        if accelerator.num_processes > 1:
            torch.distributed.all_reduce(all_rewards, op=torch.distributed.ReduceOp.SUM)

        # Convert aggregated rewards back to Python list
        rewards = all_rewards.cpu().tolist()
        # Clean up no longer needed tensor
        del all_rewards
        force_memory_cleanup()

        # Convert rewards to a tensor and normalize.
        rewards_tensor = np.array(rewards, dtype=np.float32)
        rewards_normalized = (rewards_tensor - rewards_tensor.mean()) / (rewards_tensor.std() + 1e-8)

        # Aggregate perturbations and update model weights
        if args.verbose:
            print(f"Process {accelerator.process_index} updating model weights")

        # XX why the first model?
        original_model = model_list[0]
        seed_shift_value = 0
        for name, param in original_model.named_parameters():
            gen = torch.Generator(device=param.device)
            update = torch.zeros_like(param)
            for seed_idx in range(POPULATION_SIZE):
                r_norm = rewards_normalized[seed_idx]
                seed = seeds[seed_idx]
                if args.seed_shift:
                    gen.manual_seed(int(seed + seed_shift_value))
                else:
                    gen.manual_seed(int(seed))

                noise = torch.randn(param.shape, generator=gen, device=param.device, dtype=param.dtype)
                noise.mul_(float(r_norm))
                update.add_(noise)
                del noise
            update.div_(POPULATION_SIZE)
            param.data.add_(ALPHA * update)
            torch.cuda.empty_cache()
            seed_shift_value += 1

        for model_idx in range(1, len(model_list)):
            original_model_tmp = model_list[model_idx]
            for name, param in original_model_tmp.named_parameters():
                param.data.copy_(original_model.get_parameter(name).data.clone())

        # Synchronize to ensure weight updates are complete
        if torch.cuda.is_available():
            torch.cuda.synchronize(accelerator.device)

        force_memory_cleanup()

        iter_time = time.time() - iter_start_time

        mean_reward = rewards_tensor.mean().item()
        min_reward = rewards_tensor.min().item()
        max_reward = rewards_tensor.max().item()

        del rewards_tensor, rewards_normalized
        force_memory_cleanup()

        if accelerator.is_main_process:
            print(
                f"Iteration {iteration + 1}/{NUM_ITERATIONS}, Time: {iter_time:.2f}s, \
                    Mean: {mean_reward:.2f}, Min: {min_reward:.2f}, Max: {max_reward:.2f}"
            )
            print(
                f"GPU Memory: {torch.cuda.memory_allocated() / 1024**2:.2f}MB allocated, \
                    {torch.cuda.max_memory_allocated() / 1024**2:.2f}MB peak"
            )

    total_time = time.time() - training_start_time

    # Save the fine-tuned model weights.
    if accelerator.is_main_process:
        print(f"Training completed in {total_time:.2f}s ({total_time/60:.2f} minutes)")
        question_num = len(dataset)
        save_dir = (
            f"finetuned_{model_name}_es_random_seed{INITIAL_SEED}_pop{POPULATION_SIZE}_iter{NUM_ITERATIONS}"
            f"_sigma{SIGMA}_alpha{ALPHA}_{args.precision}_threads{args.gpu_threads}_question_num{question_num}_correct"
        )
        print(f"Saving model to {save_dir}...")
        original_model.save_pretrained(save_dir)
        tokenizer.save_pretrained(save_dir)
        print("Model saved successfully.")


if __name__ == "__main__":
    cli_args = parse_args()
    main(cli_args)
